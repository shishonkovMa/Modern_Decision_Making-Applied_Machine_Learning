{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice assignment: Handling categorical data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3dZEp05rN8tN"
   },
   "source": [
    "In this programming assignment, you are going to work with the following dataset from Kaggle:\n",
    "\n",
    "https://www.kaggle.com/arashnic/hr-analytics-job-change-of-data-scientists\n",
    "\n",
    "This assignment is graded by your `submission.json`.\n",
    "\n",
    "The cell below creates a valid `submission.json` file, fill your answers in there. \n",
    "\n",
    "You can press \"Submit Assignment\" at any time to submit partial progress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting submission.json\n"
     ]
    }
   ],
   "source": [
    "%%file submission.json\n",
    "{\n",
    "    \"q1\": 0,\n",
    "    \"q2\": 0,\n",
    "    \"q3\": 0,\n",
    "    \"q4\": 0,\n",
    "    \"q5\": 0,\n",
    "    \"q6\": 0,\n",
    "    \"q7\": 0,\n",
    "    \"q8\": 0,\n",
    "    \"q9\": 0,\n",
    "    \"q10\": 0,\n",
    "    \"q11\": 0,\n",
    "    \"q12\": 0,\n",
    "    \"q13\": 0,\n",
    "    \"q14\": 0,\n",
    "    \"q15\": 0,\n",
    "    \"q16\": \"\",\n",
    "    \"q17\": 0\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "\n",
    "Suppose that a company working with Big Data and Data Science wants to hire data scientists among people who have successfully passed some courses conducted by the company. Many people sign up for their training. The company wants to focus of the candidates who really want to work for them after training. Information related to demographics, education, experience is provided by the candidates via a sign-up form.\n",
    "\n",
    "This dataset is designed to understand the factors that lead a person to leave current job which is useful for HR researches. Based on the provided data, you are going to predict whether a candidate is looking for a job change.\n",
    "\n",
    "The whole data is divided into train and test parts. Data contains several categorical features – they need to be encoded.\n",
    "\n",
    "## Feature description\n",
    "\n",
    "- `enrollee_id`: Unique ID for a candidate\n",
    "- `city`: City code\n",
    "- `city_development_index`: Developement index of the city (scaled)\n",
    "- `gender`: Gender of a candidate\n",
    "- `relevent_experience`: Relevant experience of a candidate\n",
    "- `enrolled_university`: Type of University course enrolled in if any\n",
    "- `education_level`: Education level of a candidate\n",
    "- `major_discipline`: Education major discipline of a candidate\n",
    "- `experience`: Candidate total experience in years\n",
    "- `company_size`: Number of employees in a current employer's company\n",
    "- `company_type`: Type of a current employer\n",
    "- `last_new_job`: Difference in years between previous and current jobs\n",
    "- `training_hours`: training hours completed\n",
    "- `target`: 0 – Not looking for job change, 1 – Looking for a job change\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-riW7UN88QB0"
   },
   "source": [
    "## 1\n",
    "\n",
    "Before modifying the features, let's study our dataframe a bit. First, call `.dtypes` for `train` dataframe. \n",
    "\n",
    "**q1:** How many columns in `train` contain data types different from numbers (ints and floats)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "TLmsIbke6RTE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19158 entries, 0 to 19157\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   enrollee_id             19158 non-null  int64  \n",
      " 1   city                    19158 non-null  object \n",
      " 2   city_development_index  19158 non-null  float64\n",
      " 3   gender                  14650 non-null  object \n",
      " 4   relevent_experience     19158 non-null  object \n",
      " 5   enrolled_university     18772 non-null  object \n",
      " 6   education_level         18698 non-null  object \n",
      " 7   major_discipline        16345 non-null  object \n",
      " 8   experience              19093 non-null  object \n",
      " 9   company_size            13220 non-null  object \n",
      " 10  company_type            13018 non-null  object \n",
      " 11  last_new_job            18735 non-null  object \n",
      " 12  training_hours          19158 non-null  int64  \n",
      " 13  target                  19158 non-null  float64\n",
      "dtypes: float64(2), int64(2), object(10)\n",
      "memory usage: 2.0+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "display(train.info())\n",
    "len(train.columns[train.dtypes == 'object'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aZmIR0DeNj-4"
   },
   "source": [
    "## 2\n",
    "\n",
    "**q2:** How many unique caterogies does a feature `'city'` contain in the train data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "w1OFKy0S6SdX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "train.city.value_counts().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zT4YJ6DaOjF7"
   },
   "source": [
    "## 3\n",
    "\n",
    "**q3:** How many features in train data contain missing values (NaN)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BaEwQjRg6Tj_"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "enrollee_id                  0\n",
       "city                         0\n",
       "city_development_index       0\n",
       "gender                    4508\n",
       "relevent_experience          0\n",
       "enrolled_university        386\n",
       "education_level            460\n",
       "major_discipline          2813\n",
       "experience                  65\n",
       "company_size              5938\n",
       "company_type              6140\n",
       "last_new_job               423\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "count = 0\n",
    "for i in train.isna().sum():\n",
    "    if i != 0:\n",
    "        count += 1\n",
    "display(count)\n",
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxc_ZFXyQ2lc"
   },
   "source": [
    "## 4\n",
    "\n",
    "Some features have a relatively small number of missing values. For instance, `'experience'` has only 65 missing values in the train data. Replacing these missing values with a special category might introduce bias to the data. However, since the number of missing values is not so big, we might be OK with it.\n",
    "\n",
    "Replace missing values in `'experience'` feature with a category -1.\n",
    "\n",
    "**q4:** How many categories does this feature contain in the train data now?\n",
    "\n",
    "_(hint: you might want to use `fillna` function from `pandas` library in this task, but remember that it's not an in-place function by default. Or you can use `SimpleImputer` from `sklearn`)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "dWv8Npro6VA1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "train.experience.fillna(value=-1, inplace=True)\n",
    "len(train.experience.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Od7G5iQ2ZVNB"
   },
   "source": [
    "## 5\n",
    "\n",
    "`'education_level'` is an example of an ordinal feature. Sure, we can define an order on it. For instance, `'High School'` is \"bigger\" than `'Primary School'`, and `'Phd'` is \"bigger\" than '`Graduate'`. We can encode this feature with integer numbers in a correct order.\n",
    "\n",
    "In this task, apply a correct mapping for the values of `'education_level'` feature. The mapping should be the following:\n",
    "\n",
    "* `'Primary School'` -> 0\n",
    "* `'High School'` -> 1\n",
    "* `'Graduate'` -> 2\n",
    "* `'Masters'` -> 3\n",
    "* `'Phd'` -> 4\n",
    "\n",
    "At the same time, impute missing values in `'education_level'` with a new category -1. So another part of the mapping would be:\n",
    "\n",
    "* `np.nan` -> -1\n",
    "\n",
    "**q5:** What will be the mean value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest TWO decimal places (e.g. 12.3456789 -> 12.35).\n",
    "\n",
    "_(hint: you might want to use `map` function from `pandas` in this task)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "BKDebpQX6WL7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.06"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_education = {\n",
    "    'Primary School': 0,\n",
    "    'High School': 1,\n",
    "    'Graduate': 2,\n",
    "    'Masters': 3,\n",
    "    'Phd': 4,\n",
    "    np.nan: -1\n",
    "}# your code here\n",
    "# your code here\n",
    "train.education_level.replace(map_education, inplace=True)\n",
    "np.round(np.mean(train.education_level), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NAi9S-YBrOlY"
   },
   "source": [
    "## 6\n",
    "\n",
    "Feature `'relevent_experience'` is an example of a binary feature. You can also check that it has no missing values, which makes its encoding pretty easy.\n",
    "\n",
    "Encode this feature with the following mapping:\n",
    "\n",
    "*   `\"No relevent experience\"` -> 0\n",
    "*   `\"Has relevent experience\"` -> 1\n",
    "\n",
    "**q6:** What will be the mean value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest TWO decimal places (e.g. 12.3456789 -> 12.35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "l5uTrVl36XjM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.72"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_relevent_experience = {\n",
    "    \"No relevent experience\": 0,\n",
    "    \"Has relevent experience\": 1\n",
    "}# your code here\n",
    "# your code here\n",
    "train.relevent_experience.replace(map_relevent_experience, inplace=True)\n",
    "np.round(np.mean(train.relevent_experience), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Lv-zgcIDtzqR"
   },
   "source": [
    "## 7\n",
    "\n",
    "In our case, `'gender'` is an example of a nominal feature (notice that it is not a binary feature cause it contains three categories + NaNs). We will use One-Hot encoding to encode it. There are several options how to do it in practice: for example, to use `get_dummies` function from `pandas` or `OneHotEncoder` from `sklearn.preprocessing`. Here, we will go with the first option.\n",
    "\n",
    "If you want to encode a whole dataset with One-Hot encoding, you can directly pass it into the discussed methods. But here we want to encode only one feature. We suggest to do it in four steps:\n",
    "\n",
    "1. Obtain a One-Hot encoding dataframe for the feature `'gender'`: apply `pd.get_dummies` to this feature. As a result, you should obtain a dataframe with three features (three different categories for gender). Don't include `'NaN'` feature - it will already be included as the encoding (0, 0, 0).\n",
    "2. Change the column names of this dataframe, so that a feature `'<category_name>'` will become `'gender-<category_name>'`. Of course, it is not a necessary step in general. However, it probably would be more convenient to work with a full dataframe if we remember that these One-Hot encoded features originally came from the feature `'gender'`. On a technical side, you can perform it by changing `df_gender.columns` list.\n",
    "3. Concatenate original and new dataframes. You can do it by calling `pd.concat` function. Don't forget to set `'axis'` parameter, so that you concatenate dataframes by columns, not by rows. As a result of this step, you should obtain a new `train` dataframe with three new columns named like `'gender-<category_name>'`.\n",
    "4. Finally, drop `'gender'` feature because we have already encoded it.\n",
    "\n",
    "As a result of these four steps, you should obtain a new version of `train` dataframe, with dropped `'gender'` feature and three new features named like `'gender-<category_name>'`. A total number of columns by this time should be equal to 16.\n",
    "\n",
    "**q7:** What is the total number of zero values which appear in the columns starting with `'gender-'`?\n",
    "\n",
    "_Example: suppose that you obtain the following dataframe:_\n",
    "\n",
    "| gender-category1 | gender-category2   | gender-category3|\n",
    "|------|------|------|\n",
    "|   0  | 1| 0|\n",
    "|0|0|0|\n",
    "\n",
    "_Then the answer for the question above should be 5._\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "7IGy0CV96Y8Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42824"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>gender-Female</th>\n",
       "      <th>gender-Male</th>\n",
       "      <th>gender-Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28120</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31820</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>2</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Early Stage Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4277</td>\n",
       "      <td>city_71</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>Part time course</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3379</td>\n",
       "      <td>city_159</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10821</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>8241</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>18441</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>29117</td>\n",
       "      <td>city_11</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0</td>\n",
       "      <td>Full time course</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>27929</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>10000+</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>4269</td>\n",
       "      <td>city_67</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1</td>\n",
       "      <td>no_enrollment</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>14</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollee_id      city  city_development_index  relevent_experience  \\\n",
       "0            28120   city_16                   0.910                    1   \n",
       "1            31820   city_21                   0.624                    0   \n",
       "2             4277   city_71                   0.884                    1   \n",
       "3             3379  city_159                   0.843                    1   \n",
       "4            10821   city_16                   0.910                    1   \n",
       "...            ...       ...                     ...                  ...   \n",
       "19153         8241   city_16                   0.910                    1   \n",
       "19154        18441  city_103                   0.920                    1   \n",
       "19155        29117   city_11                   0.550                    0   \n",
       "19156        27929  city_103                   0.920                    0   \n",
       "19157         4269   city_67                   0.855                    1   \n",
       "\n",
       "      enrolled_university  education_level major_discipline experience  \\\n",
       "0           no_enrollment              1.0              NaN         19   \n",
       "1           no_enrollment              3.0             STEM          2   \n",
       "2        Part time course              2.0             STEM        >20   \n",
       "3           no_enrollment              3.0             STEM        >20   \n",
       "4           no_enrollment              3.0             STEM          6   \n",
       "...                   ...              ...              ...        ...   \n",
       "19153       no_enrollment             -1.0              NaN         11   \n",
       "19154       no_enrollment              2.0             STEM        >20   \n",
       "19155    Full time course              2.0             STEM         <1   \n",
       "19156       no_enrollment              2.0             STEM         15   \n",
       "19157       no_enrollment              2.0             STEM         14   \n",
       "\n",
       "      company_size         company_type last_new_job  training_hours  target  \\\n",
       "0          100-500              Pvt Ltd            2              20     0.0   \n",
       "1            50-99  Early Stage Startup            1              10     1.0   \n",
       "2              NaN                  NaN            2               6     1.0   \n",
       "3              <10              Pvt Ltd           >4              56     0.0   \n",
       "4              NaN                  NaN            4              15     0.0   \n",
       "...            ...                  ...          ...             ...     ...   \n",
       "19153          NaN                  NaN            1               4     0.0   \n",
       "19154          NaN                  NaN           >4              56     1.0   \n",
       "19155          NaN                  NaN        never              12     0.0   \n",
       "19156       10000+              Pvt Ltd            2              16     1.0   \n",
       "19157        50-99              Pvt Ltd            2              72     0.0   \n",
       "\n",
       "       gender-Female  gender-Male  gender-Other  \n",
       "0                  0            0             0  \n",
       "1                  0            0             0  \n",
       "2                  0            1             0  \n",
       "3                  0            1             0  \n",
       "4                  0            1             0  \n",
       "...              ...          ...           ...  \n",
       "19153              0            0             0  \n",
       "19154              0            0             0  \n",
       "19155              0            0             0  \n",
       "19156              0            1             0  \n",
       "19157              1            0             0  \n",
       "\n",
       "[19158 rows x 16 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "gender_df = pd.get_dummies(train.gender)\n",
    "gender_df.rename(columns = {'Female': 'gender-Female', \n",
    "                           'Male': 'gender-Male', \n",
    "                           'Other': 'gender-Other'}, \n",
    "                 inplace=True)\n",
    "display(len(gender_df)*3 - gender_df.sum().sum())\n",
    "train = pd.concat([train, gender_df], axis=1)\n",
    "train.drop('gender', axis=1, inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJx2G8ZQv_Hy"
   },
   "source": [
    "## 8\n",
    "\n",
    "Perform One-Hot encoding for the feature `'enrolled_university'`, using the similar procedure as in the previous task:\n",
    "\n",
    "1. Obtain a One-Hot encoding dataframe for `'enrolled_university'`.\n",
    "2. Rename its columns.\n",
    "3. Concatenate original and One-Hot encoding dataframes.\n",
    "4. Drop `'enrolled_university'` column.\n",
    "\n",
    "A total number of columns by this time should be equal to 18.\n",
    "\n",
    "**q8:** What is the total number of zero values which appear in the columns starting with `'enrolled_university-'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TrHkhli66aPP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "38702"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>major_discipline</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "      <th>gender-Female</th>\n",
       "      <th>gender-Male</th>\n",
       "      <th>gender-Other</th>\n",
       "      <th>enrolled_university-Full_time_course</th>\n",
       "      <th>enrolled_university-Part_time_course</th>\n",
       "      <th>enrolled_university-no_enrollment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28120</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19</td>\n",
       "      <td>100-500</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31820</td>\n",
       "      <td>city_21</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>2</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Early Stage Startup</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4277</td>\n",
       "      <td>city_71</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3379</td>\n",
       "      <td>city_159</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>&lt;10</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10821</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>8241</td>\n",
       "      <td>city_16</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>18441</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&gt;20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>&gt;4</td>\n",
       "      <td>56</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>29117</td>\n",
       "      <td>city_11</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>&lt;1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>never</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>27929</td>\n",
       "      <td>city_103</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>15</td>\n",
       "      <td>10000+</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>4269</td>\n",
       "      <td>city_67</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>STEM</td>\n",
       "      <td>14</td>\n",
       "      <td>50-99</td>\n",
       "      <td>Pvt Ltd</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       enrollee_id      city  city_development_index  relevent_experience  \\\n",
       "0            28120   city_16                   0.910                    1   \n",
       "1            31820   city_21                   0.624                    0   \n",
       "2             4277   city_71                   0.884                    1   \n",
       "3             3379  city_159                   0.843                    1   \n",
       "4            10821   city_16                   0.910                    1   \n",
       "...            ...       ...                     ...                  ...   \n",
       "19153         8241   city_16                   0.910                    1   \n",
       "19154        18441  city_103                   0.920                    1   \n",
       "19155        29117   city_11                   0.550                    0   \n",
       "19156        27929  city_103                   0.920                    0   \n",
       "19157         4269   city_67                   0.855                    1   \n",
       "\n",
       "       education_level major_discipline experience company_size  \\\n",
       "0                  1.0              NaN         19      100-500   \n",
       "1                  3.0             STEM          2        50-99   \n",
       "2                  2.0             STEM        >20          NaN   \n",
       "3                  3.0             STEM        >20          <10   \n",
       "4                  3.0             STEM          6          NaN   \n",
       "...                ...              ...        ...          ...   \n",
       "19153             -1.0              NaN         11          NaN   \n",
       "19154              2.0             STEM        >20          NaN   \n",
       "19155              2.0             STEM         <1          NaN   \n",
       "19156              2.0             STEM         15       10000+   \n",
       "19157              2.0             STEM         14        50-99   \n",
       "\n",
       "              company_type last_new_job  training_hours  target  \\\n",
       "0                  Pvt Ltd            2              20     0.0   \n",
       "1      Early Stage Startup            1              10     1.0   \n",
       "2                      NaN            2               6     1.0   \n",
       "3                  Pvt Ltd           >4              56     0.0   \n",
       "4                      NaN            4              15     0.0   \n",
       "...                    ...          ...             ...     ...   \n",
       "19153                  NaN            1               4     0.0   \n",
       "19154                  NaN           >4              56     1.0   \n",
       "19155                  NaN        never              12     0.0   \n",
       "19156              Pvt Ltd            2              16     1.0   \n",
       "19157              Pvt Ltd            2              72     0.0   \n",
       "\n",
       "       gender-Female  gender-Male  gender-Other  \\\n",
       "0                  0            0             0   \n",
       "1                  0            0             0   \n",
       "2                  0            1             0   \n",
       "3                  0            1             0   \n",
       "4                  0            1             0   \n",
       "...              ...          ...           ...   \n",
       "19153              0            0             0   \n",
       "19154              0            0             0   \n",
       "19155              0            0             0   \n",
       "19156              0            1             0   \n",
       "19157              1            0             0   \n",
       "\n",
       "       enrolled_university-Full_time_course  \\\n",
       "0                                         0   \n",
       "1                                         0   \n",
       "2                                         0   \n",
       "3                                         0   \n",
       "4                                         0   \n",
       "...                                     ...   \n",
       "19153                                     0   \n",
       "19154                                     0   \n",
       "19155                                     1   \n",
       "19156                                     0   \n",
       "19157                                     0   \n",
       "\n",
       "       enrolled_university-Part_time_course  enrolled_university-no_enrollment  \n",
       "0                                         0                                  1  \n",
       "1                                         0                                  1  \n",
       "2                                         1                                  0  \n",
       "3                                         0                                  1  \n",
       "4                                         0                                  1  \n",
       "...                                     ...                                ...  \n",
       "19153                                     0                                  1  \n",
       "19154                                     0                                  1  \n",
       "19155                                     0                                  0  \n",
       "19156                                     0                                  1  \n",
       "19157                                     0                                  1  \n",
       "\n",
       "[19158 rows x 18 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# your code here\n",
    "enrolled_university_df = pd.get_dummies(train.enrolled_university)\n",
    "enrolled_university_df\n",
    "enrolled_university_df.rename(columns = {'Full time course': 'enrolled_university-Full_time_course', \n",
    "                                         'Part time course': 'enrolled_university-Part_time_course', \n",
    "                                         'no_enrollment': 'enrolled_university-no_enrollment'}, \n",
    "                              inplace=True)\n",
    "display(len(enrolled_university_df)*3 - enrolled_university_df.sum().sum())\n",
    "train = pd.concat([train, enrolled_university_df], axis=1)\n",
    "train.drop('enrolled_university', axis=1, inplace=True)\n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UBervQFY9N7K"
   },
   "source": [
    "## 9\n",
    "\n",
    "Encode feature `'city'` using frequency encoding. You should map each category `'city_i'` to its count (a total number of observations in `train` with `city == 'city_i'`). Save this mapping, since later you would apply the same mapping to the test data.\n",
    "\n",
    "As a result of this task, feature `'city'` should be encoded with category counts in `train`. \n",
    "\n",
    "**q9:** What will be the mean value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Co-kiLuc6bO6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1709.79643"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_city = train.groupby('city')['city'].count()# your code here\n",
    "# your code here\n",
    "train['city'] = train['city'].apply(lambda x : map_city[x])\n",
    "np.round(np.mean(train.city), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ksJw_j-M9XCC"
   },
   "source": [
    "## 10\n",
    "\n",
    "Encode feature `'last_new_job'` with target encoding with no modifications. First, impute missing values in this feature with a new category `'-1'`. Then, map each category of `'last_new_job'` to the mean target value of the observations with the corresponding category. Save this mapping, since later you would apply the same mapping to the test data.\n",
    "\n",
    "**q10:** What will be the maximum value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.35).\n",
    "\n",
    "_(hint: you might want to use `groupby` function from `pandas` in this task)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tmZgKA1_6caQ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36407"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.last_new_job.fillna(value=-1, inplace=True)# your code here\n",
    "map_last_new_job = train.groupby('last_new_job')['target'].mean()# your code here\n",
    "train['last_new_job'] = train['last_new_job'].apply(lambda x : map_last_new_job[x])\n",
    "np.round(np.max(train.last_new_job), 5)# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyIVTPEY9eLb"
   },
   "source": [
    "## 11\n",
    "\n",
    "Encode feature `'experience'` with M-estimate encoding. Map each category of `'experience'` according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\frac{\\text{target}\\left(j, x_{ij}\\right) + m\\times y_{\\text{mean}}}{\\text{count}\\left(j, x_{ij}\\right) + m}\\quad,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $x_{ij}$ is a category being encoded,\n",
    "* $\\hat{x_{ij}}$ is its corresponding M-estimate encoding value,\n",
    "* $\\text{count}\\left(j, x_{ij}\\right)$ is a total number of times $x_{ij}$ appeared in `train`,\n",
    "* $\\text{target}\\left(j, x_{ij}\\right)$ is a mean target value of the observations with the corresponding category,\n",
    "* $m$ is a parameter.\n",
    "\n",
    "In this task, set $m = 0.5$. \n",
    "\n",
    "**q11:** What will be the maximum value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "cbihpCuH6dxL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45383"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders.m_estimate import MEstimateEncoder\n",
    "\n",
    "encoder_m_est = MEstimateEncoder(m=0.5)\n",
    "encoder_m_est.fit(train.experience, train.target)\n",
    "train['experience'] = encoder_m_est.transform(train.experience)\n",
    "np.round(np.max(train.experience), 5)# your code here\n",
    "\n",
    "# m = 0.5\n",
    "# map_experience = ((train.groupby('experience')['target'].mean() + m * train.target.mean()) / \n",
    "#                  (train.groupby('experience')['experience'].count() + m))# your code here\n",
    "# train['experience'] = train['experience'].apply(lambda x : map_experience[x])\n",
    "# np.round(np.max(train.experience), 5)# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0eCGRxLLJ-Y"
   },
   "source": [
    "## 12\n",
    "\n",
    "Encode feature `'major_discipline'` with Leave-One-Out encoding. Remember that this technique is similar to target encoding, but here while computing the encoding for a particular observation, we exclude it from the target encoding formula. Therefore a category $x_{ij}$ for the $i$-th observation will be encoded according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\frac{\\text{target}\\left(j, x_{ij}\\right) - y_i}{\\text{count}\\left(j, x_{ij}\\right) - 1}\\quad,\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "* $\\hat{x_{ij}}$ is its corresponding M-estimate encoding value,\n",
    "* $\\text{count}\\left(j, x_{ij}\\right)$ is a total number of times $x_{ij}$ appeared in `train`,\n",
    "* $\\text{target}\\left(j, x_{ij}\\right)$ is a mean target value of the observations with the corresponding category,\n",
    "* $y_i$ is a target value of the $i$-th observation\n",
    "\n",
    "For example, suppose that you have the following train data:\n",
    "\n",
    "|feature|target|\n",
    "|-|-|\n",
    "|A|1|\n",
    "|A|0|\n",
    "|B|1|\n",
    "|B|0|\n",
    "|A|0|\n",
    "\n",
    "Then you obtain the following Leave-One-Out encoding:\n",
    "\n",
    "|feature|feature_loo_encoded|\n",
    "|-|-|\n",
    "|A|0.0|\n",
    "|A|0.5|\n",
    "|B|0.0|\n",
    "|B|1.0|\n",
    "|A|0.5|\n",
    "\n",
    "It is very important to notice that in this method the same category can be encoded differently for different observations. Thus, after encoding the train part of data, you should create a mapping which will help to encode the test data. In order to do this, simply average train encoding values within each category to obtain the final encoding. For instance, suppose that you obtain the following train dataframe:\n",
    "\n",
    "|feature|feature_loo_encoded|\n",
    "|-|-|\n",
    "|A|0.2|\n",
    "|A|0.6|\n",
    "|B|0.3|\n",
    "|B|0.7|\n",
    "|A|0.4|\n",
    "\n",
    "Then, for the test data, you should obtain the following mapping:\n",
    "\n",
    "* A -> 0.4 (because 0.4 is a mean value of the encoded values for the category A)\n",
    "* B -> 0.5 (because 0.5 is a mean value of the encoded values for the category B)\n",
    "\n",
    "Don't impute any missing values in this task. After completing this task, drop the feature `'major_discipline'` and rename `'major_discipline_loo_encoded'` to `'major_discipline'`.\n",
    "\n",
    "**q12:** What will be the maximum value of the encoding values for `'major_discipline'` for the TEST data in the mapping described above? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "sV6QygUw6fcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.26772"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import category_encoders as ce\n",
    "\n",
    "\n",
    "encoder_leave_one_out = ce.LeaveOneOutEncoder(return_df=True)\n",
    "encoder_leave_one_out.fit(train.major_discipline, train.target)# your code here\n",
    "train['major_discipline_loo_encoded'] = encoder_leave_one_out.transform(train.major_discipline)\n",
    "map_major_discipline = train.groupby('major_discipline')['major_discipline_loo_encoded'].mean()# your code here\n",
    "train.drop('major_discipline', axis=1, inplace=True)\n",
    "train.rename(columns = {'major_discipline_loo_encoded': 'major_discipline'}, inplace=True)\n",
    "np.round(np.max(test[test['major_discipline'].notna()].major_discipline.apply(lambda x : map_major_discipline[x])), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sQmH1y-d9qOW"
   },
   "source": [
    "## 13\n",
    "\n",
    "Encode feature `'company_size'` with Catboost encoding. The technique was described in the lecture. Here, for the sake of simplicity, let's use the implementation from `category_encoders` library.\n",
    "\n",
    "As you may remember, Catboost encoding depends on how the data is ordered. Normally, you should shuffle the data one time or even several times. In this task, we will assume that the data has already been shuffled, so you don't need to shuffle it again.\n",
    "\n",
    "Take `CatBoostEncoder` and use the default values for all its parameters, except `handle_missing` - set it to `'return_nan'` so that your encoder don't do anything with missing values. Fit it on the `'company_size'` (train data) and `'target'` and transform this feature. Save the encoder - it will be used later to transform this feature in test data.\n",
    "\n",
    "Don't impute any missing values in this task.\n",
    "\n",
    "**q13:** What will be the most popular value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "PfmCVKRx6hHl"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.176799    3083\n",
       "0.161450    2571\n",
       "0.190717    2019\n",
       "0.233865    1471\n",
       "0.150677    1328\n",
       "0.171313    1308\n",
       "0.173405     877\n",
       "0.181293     563\n",
       "Name: company_size, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from category_encoders.cat_boost import CatBoostEncoder\n",
    "# your code here\n",
    "encoder_catboost = CatBoostEncoder(handle_missing='return_nan')\n",
    "encoder_catboost.fit(train.company_size, train.target)\n",
    "train['company_size'] = encoder_catboost.transform(train.company_size)\n",
    "train['company_size'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBE4sCLL9uV4"
   },
   "source": [
    "## 14\n",
    "\n",
    "Encode feature `'company_type'` with Weight of Evidence (WoE) encoding. A category $x_{ij}$ will be encoded according to the following formula:\n",
    "\n",
    "$$\n",
    "\\hat{x_{ij}} = \\ln\\left(\\frac{\\mathbb{P}\\left(x_{ij}\\mid y=1\\right)}{\\mathbb{P}\\left(x_{ij}\\mid y=0\\right)}\\right)\\quad.\n",
    "$$\n",
    "\n",
    "Here:\n",
    "\n",
    "$$\n",
    "\\mathbb{P}\\left(x_{ij}\\mid y=1\\right) = \\frac{\\text{count}\\left(y=1\\mid x_{ij}\\right)}{\\text{count}\\left(y=1\\right)}\n",
    "$$\n",
    "$$\n",
    "\\mathbb{P}\\left(x_{ij}\\mid y=0\\right) = \\frac{\\text{count}\\left(y=0\\mid x_{ij}\\right)}{\\text{count}\\left(y=0\\right)}\n",
    "$$\n",
    "\n",
    "The notation means the following:\n",
    "\n",
    "* $\\text{count}\\left(y=1\\mid x_{ij}\\right)$ denotes the number of observations with the category $x_{ij}$ where the target value is equal to $1$;\n",
    "* $\\text{count}\\left(y=0\\mid x_{ij}\\right)$ denotes the same but for the target value $0$;\n",
    "* $\\text{count}\\left(y=1\\right)$ denotes the number of observations with the target value equal to $1$;\n",
    "* $\\text{count}\\left(y=0\\right)$ denotes the same but for the target value $0$.\n",
    "\n",
    "\n",
    "For example, suppose that you have the following train data:\n",
    "\n",
    "|feature|target|\n",
    "|-|-|\n",
    "|A|1|\n",
    "|A|0|\n",
    "|B|1|\n",
    "|B|0|\n",
    "|A|0|\n",
    "\n",
    "Then you obtain the following WoE encoding mapping:\n",
    "\n",
    "* A -> $\\ln\\left(\\frac{\\frac{1}{2}}{\\frac{2}{3}}\\right) \\approx -0.288$ \n",
    "* B -> $\\ln\\left(\\frac{\\frac{1}{2}}{\\frac{1}{3}}\\right) \\approx 0.405$ \n",
    "\n",
    "Don't impute any missing values in this task.\n",
    "\n",
    "**q14:** What will be the most popular value of this feature in the train data after the encoding? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "A52TWXmH6igK"
   },
   "outputs": [],
   "source": [
    "map_company_type = np.log((train[train.target == 1].groupby('company_type')['company_type'].count() /\n",
    "                          len(train[train.target == 1])) /\n",
    "                         (train[train.target == 0].groupby('company_type')['company_type'].count() /\n",
    "                          len(train[train.target == 0])))# your code here\n",
    "# your code here\n",
    "train['company_type'] = train[train['company_type'].notna()].company_type.apply(lambda x : map_company_type[x])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wFwADkfU9wxD"
   },
   "source": [
    "## 15\n",
    "\n",
    "We have encoded all categorical features. Next, we drop `'enrollee_id'` because it is not a representative feature. After this, we split train part of data into the dataframe which contains only features (without target) and the target array.\n",
    "\n",
    "Before training the models, we should impute the remaining missing values. You might have noticed that we didn't impute missing values for the features `'major_discipline'`, `'company_size'` and `'company_type'`. This is because the number of missing values in these features is relatively big (you can check it yourself). In practice, you might just create a special category (like `'-1'`) for each of these features before the encoding. However, in this task, let's perform the imputation using KNN approach - where we impute missing values by looking at the similar observations.\n",
    "\n",
    "Import `KNNImputer` from `sklearn`. It works only with the dataset with numbers - this is why we didn't run it before the encoding. Set `n_neighbors=3`, and let other parameters have the default values. Fit it on the train dataframe with features, and then transform it. Notice that after the transformation we will obtain `numpy.array` - make `pandas.DataFrame` out of it with the same columns as before.\n",
    "\n",
    "Save the KNN imputer - you will need it to process the test data. Check that there are no missing values in the train data anymore.\n",
    "\n",
    "**q15:** What is the mean value of the `'company_size'` feature in the train data after the imputation? Provide the answer, rounded to the nearest FIVE decimal places (e.g. 12.3456789 -> 12.34568)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 632,
     "status": "ok",
     "timestamp": 1610996515882,
     "user": {
      "displayName": "Evgeny Kovalev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapCcPAzYLJE2xqpH7xgS8qtR8bZrkCgbHm27oLg=s64",
      "userId": "07828702499945486090"
     },
     "user_tz": -180
    },
    "id": "eCz_Pr_xoa82",
    "outputId": "1457ef28-3783-488e-ea52-fc79f2e6f893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19158, 16), (19158,))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = train.drop(['enrollee_id', 'target'], axis=1)\n",
    "y_train = train['target']\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "YvfwLqvS6kKr",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>education_level</th>\n",
       "      <th>experience</th>\n",
       "      <th>company_size</th>\n",
       "      <th>company_type</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>gender-Female</th>\n",
       "      <th>gender-Male</th>\n",
       "      <th>gender-Other</th>\n",
       "      <th>enrolled_university-Full_time_course</th>\n",
       "      <th>enrolled_university-Part_time_course</th>\n",
       "      <th>enrolled_university-no_enrollment</th>\n",
       "      <th>major_discipline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.174465</td>\n",
       "      <td>0.161450</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.195165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2702.0</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.331818</td>\n",
       "      <td>0.176799</td>\n",
       "      <td>-0.075476</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>266.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.162975</td>\n",
       "      <td>-0.429107</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.843</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.171313</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.282059</td>\n",
       "      <td>0.164435</td>\n",
       "      <td>-0.297680</td>\n",
       "      <td>0.221574</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19153</th>\n",
       "      <td>1533.0</td>\n",
       "      <td>0.910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.227426</td>\n",
       "      <td>0.190705</td>\n",
       "      <td>-0.327249</td>\n",
       "      <td>0.264303</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.195165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19154</th>\n",
       "      <td>4355.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.153088</td>\n",
       "      <td>0.180307</td>\n",
       "      <td>-0.327249</td>\n",
       "      <td>0.182371</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19155</th>\n",
       "      <td>247.0</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.453827</td>\n",
       "      <td>0.174971</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.301387</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19156</th>\n",
       "      <td>4355.0</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.166241</td>\n",
       "      <td>0.190717</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19157</th>\n",
       "      <td>431.0</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.182651</td>\n",
       "      <td>0.176799</td>\n",
       "      <td>-0.408782</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>72.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.261593</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19158 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         city  city_development_index  relevent_experience  education_level  \\\n",
       "0      1533.0                   0.910                  1.0              1.0   \n",
       "1      2702.0                   0.624                  0.0              3.0   \n",
       "2       266.0                   0.884                  1.0              2.0   \n",
       "3        94.0                   0.843                  1.0              3.0   \n",
       "4      1533.0                   0.910                  1.0              3.0   \n",
       "...       ...                     ...                  ...              ...   \n",
       "19153  1533.0                   0.910                  1.0             -1.0   \n",
       "19154  4355.0                   0.920                  1.0              2.0   \n",
       "19155   247.0                   0.550                  0.0              2.0   \n",
       "19156  4355.0                   0.920                  0.0              2.0   \n",
       "19157   431.0                   0.855                  1.0              2.0   \n",
       "\n",
       "       experience  company_size  company_type  last_new_job  training_hours  \\\n",
       "0        0.174465      0.161450     -0.408782      0.241379            20.0   \n",
       "1        0.331818      0.176799     -0.075476      0.264303            10.0   \n",
       "2        0.153088      0.162975     -0.429107      0.241379             6.0   \n",
       "3        0.153088      0.171313     -0.408782      0.182371            56.0   \n",
       "4        0.282059      0.164435     -0.297680      0.221574            15.0   \n",
       "...           ...           ...           ...           ...             ...   \n",
       "19153    0.227426      0.190705     -0.327249      0.264303             4.0   \n",
       "19154    0.153088      0.180307     -0.327249      0.182371            56.0   \n",
       "19155    0.453827      0.174971     -0.408782      0.301387            12.0   \n",
       "19156    0.166241      0.190717     -0.408782      0.241379            16.0   \n",
       "19157    0.182651      0.176799     -0.408782      0.241379            72.0   \n",
       "\n",
       "       gender-Female  gender-Male  gender-Other  \\\n",
       "0                0.0          0.0           0.0   \n",
       "1                0.0          0.0           0.0   \n",
       "2                0.0          1.0           0.0   \n",
       "3                0.0          1.0           0.0   \n",
       "4                0.0          1.0           0.0   \n",
       "...              ...          ...           ...   \n",
       "19153            0.0          0.0           0.0   \n",
       "19154            0.0          0.0           0.0   \n",
       "19155            0.0          0.0           0.0   \n",
       "19156            0.0          1.0           0.0   \n",
       "19157            1.0          0.0           0.0   \n",
       "\n",
       "       enrolled_university-Full_time_course  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "19153                                   0.0   \n",
       "19154                                   0.0   \n",
       "19155                                   1.0   \n",
       "19156                                   0.0   \n",
       "19157                                   0.0   \n",
       "\n",
       "       enrolled_university-Part_time_course  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       1.0   \n",
       "3                                       0.0   \n",
       "4                                       0.0   \n",
       "...                                     ...   \n",
       "19153                                   0.0   \n",
       "19154                                   0.0   \n",
       "19155                                   0.0   \n",
       "19156                                   0.0   \n",
       "19157                                   0.0   \n",
       "\n",
       "       enrolled_university-no_enrollment  major_discipline  \n",
       "0                                    1.0          0.195165  \n",
       "1                                    1.0          0.261593  \n",
       "2                                    0.0          0.261593  \n",
       "3                                    1.0          0.261593  \n",
       "4                                    1.0          0.261593  \n",
       "...                                  ...               ...  \n",
       "19153                                1.0          0.195165  \n",
       "19154                                1.0          0.261593  \n",
       "19155                                0.0          0.261593  \n",
       "19156                                1.0          0.261593  \n",
       "19157                                1.0          0.261593  \n",
       "\n",
       "[19158 rows x 16 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 5.11 s, total: 23 s\n",
      "Wall time: 2min 6s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.17922"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "# your code here\n",
    "\n",
    "knn = KNNImputer(n_neighbors=3)\n",
    "knn.fit(X_train)\n",
    "X_train = knn.transform(X_train)\n",
    "X_train = pd.DataFrame(X_train, columns=[i for i in train.columns if i not in ['target', 'enrollee_id']])\n",
    "display(X_train)\n",
    "np.round(X_train.company_size.mean(), 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2T2a78d90mJ"
   },
   "source": [
    "## 16\n",
    "\n",
    "Finally, train a Random Forest classifier from `sklearn` on the train data. Set `n_estimators=500`, `max_depth=8`, `random_state=13`, and let other parameters have the default values. Check feature importances. \n",
    "\n",
    "**q16:** What is the name of the most important feature for this model? Provide the name of the feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "g4_1694F6l0Q"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.14936384, 0.41967012, 0.04051204, 0.03048536, 0.07535779,\n",
       "       0.05842376, 0.05589746, 0.02263798, 0.04401305, 0.00435761,\n",
       "       0.00659903, 0.00189128, 0.0330748 , 0.00464102, 0.02531344,\n",
       "       0.02776141])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# your code here\n",
    "forest = RandomForestClassifier(n_estimators=500, max_depth=8, random_state=13)\n",
    "forest.fit(X_train, y_train)\n",
    "forest.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sUydmtoi92d8"
   },
   "source": [
    "## 17\n",
    "\n",
    "In this last task, process the test data so that it is possible to make Random Forest predictions on for it. Perform the similar operations as for the train data, but remember that now you work with test observations and therefore all operations are in the inference mode.\n",
    "\n",
    "1. (task 4) Feature `'experience'`: impute missing values by -1. \n",
    "2. (task 5) Feature `'education_level'`: perform ordinal encoding mapping.\n",
    "3. (task 6) Feature `'relevent_experience'`: perform binary mapping.\n",
    "4. (task 7) Feature `'gender'`: perform One-Hot encoding and obtain three new features starting with `'gender-'`. Drop `'gender'` feature.\n",
    "5. (task 8) Feature `'enrolled_university'`: perform One-Hot encoding and obtain three new features starting with `'enrolled_university-'`. Drop `'enrolled_university'` feature.\n",
    "6. (task 9) Feature `'city'`: perform frequency encoding mapping.\n",
    "7. (task 10) Feature `'last_new_job'`: impute missing values by -1 and perform target encoding mapping.\n",
    "8. (task 11) Feature `'experience'`: perform M-estimate encoding mapping.\n",
    "9. (task 12) Feature `'major_discipline'`: perform Leave-One-Out encoding mapping.\n",
    "10. (task 13) Feature `'company_size'`: perform Catboost encoding mapping.\n",
    "11. (task 14) Feature `'company_type'`: perform WoE encoding mapping.\n",
    "12. (task 15) Split `test` into `X_test` (a dataframe with no `'enrollee_id'` and `'target'`) and `y_test` (an array with target values). Impute missing values by using KNN imputer which you used before (now only in a transform mode).\n",
    "\n",
    "As a result of the operations described above, you should obtain `X_test` which is a `pandas.DataFrame` with a shape (2129, 16). Calculate the predictions of the trained Random Forest model on it. Check the accuracy of the predictions on test data.\n",
    "\n",
    "Then calculate the predictions of the same model on `X_train` and check the accuracy there. Compare the accuracies on train and test data. Do you notice something? What, in your opinion, caused such difference in the accuracies?\n",
    "\n",
    "**q17:** As a result of this task, provide the accuracy for the test data, rounded to the nearest TWO decimal places (e.g. 12.3456789 -> 12.35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "veC-y23Fwe8L"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matu/.local/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "\n",
    "#1\n",
    "test.experience.fillna(value=-1, inplace=True)\n",
    "\n",
    "#2\n",
    "test.education_level.replace(map_education, inplace=True)\n",
    "\n",
    "#3\n",
    "test.relevent_experience.replace(map_relevent_experience, inplace=True)\n",
    "\n",
    "#4\n",
    "gender__test_df = pd.get_dummies(test.gender)\n",
    "gender__test_df.rename(columns = {'Female': 'gender-Female', \n",
    "                                  'Male': 'gender-Male', \n",
    "                                  'Other': 'gender-Other'}, \n",
    "                       inplace=True)\n",
    "test = pd.concat([test, gender__test_df], axis=1)\n",
    "test.drop('gender', axis=1, inplace=True)\n",
    "\n",
    "#5\n",
    "enrolled_university_test_df = pd.get_dummies(test.enrolled_university)\n",
    "enrolled_university_test_df.rename(columns = {'Full time course': 'enrolled_university-Full_time_course', \n",
    "                                              'Part time course': 'enrolled_university-Part_time_course', \n",
    "                                              'no_enrollment': 'enrolled_university-no_enrollment'}, \n",
    "                                   inplace=True)\n",
    "test = pd.concat([test, enrolled_university_test_df], axis=1)\n",
    "test.drop('enrolled_university', axis=1, inplace=True)\n",
    "\n",
    "#6\n",
    "test['city'] = test['city'].apply(lambda x : map_city[x])\n",
    "\n",
    "#7\n",
    "test.last_new_job.fillna(value=-1, inplace=True)\n",
    "test['last_new_job'] = test['last_new_job'].apply(lambda x : map_last_new_job[x])\n",
    "\n",
    "#8\n",
    "test['experience'] = encoder_m_est.transform(test.experience)\n",
    "\n",
    "#9\n",
    "test['major_discipline'] = test[test['major_discipline'].notna()].major_discipline.apply(lambda x : map_major_discipline[x])\n",
    "\n",
    "#10\n",
    "test['company_size'] = encoder_catboost.transform(test.company_size)\n",
    "\n",
    "#11\n",
    "test['company_type'] = test[test['company_type'].notna()].company_type.apply(lambda x : map_company_type[x])\n",
    "\n",
    "#12\n",
    "X_test = test.drop(['enrollee_id', 'target'], axis=1)\n",
    "y_test = test['target']\n",
    "X_test = knn.transform(X_test)\n",
    "X_test = pd.DataFrame(X_test, columns=[i for i in test.columns if i not in ['target', 'enrollee_id']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 752,
     "status": "ok",
     "timestamp": 1610996545175,
     "user": {
      "displayName": "Evgeny Kovalev",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhapCcPAzYLJE2xqpH7xgS8qtR8bZrkCgbHm27oLg=s64",
      "userId": "07828702499945486090"
     },
     "user_tz": -180
    },
    "id": "4kK-7S1Q16lp",
    "outputId": "b5b5ea5a-e883-4349-b9d8-fe0c91eae5a1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2129, 16)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "yM1CI29I6rv5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/matu/.local/lib/python3.8/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names must be in the same order as they were in fit.\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-score 0.8\n",
      "test-score 0.78\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# your code here\n",
    "train_predictions = forest.predict(X_train)\n",
    "test_predictions = forest.predict(X_test)\n",
    "\n",
    "print('train-score', np.round(accuracy_score(train_predictions, y_train), 2))\n",
    "print('test-score', np.round(accuracy_score(test_predictions, y_test), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO77HBmz1/PpQ55VCcYPEhx",
   "collapsed_sections": [],
   "name": "Week1_practice.ipynb",
   "provenance": [
    {
     "file_id": "1WztG2ZwKA0bx5LJIEQNQH23OULDBBmt8",
     "timestamp": 1610996564372
    }
   ]
  },
  "coursera": {
   "schema_names": [
    "categorical-data-task-week-1-1"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
